{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73aeb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os    \n",
    "import data_processing as dp     \n",
    "import timeit                                                        \n",
    "# import pydca-ER module           \n",
    "import matplotlib  \n",
    "#matplotlib.use('agg')               \n",
    "import matplotlib.pyplot as plt                  \n",
    "from scipy import linalg  \n",
    "from sklearn.preprocessing import OneHotEncoder                              \n",
    "import expectation_reflection as ER  \n",
    "from direct_info import direct_info                                                                      \n",
    "from direct_info import sort_di                                                      \n",
    "from joblib import Parallel, delayed                                                \n",
    "import numpy as np                                                                                       \n",
    "import pickle   \n",
    "from Bio import Phylo                                                                                    \n",
    "import networkx, pylab                                                                                   \n",
    "import pandas as pd \n",
    "import Bio.SubsMat.FreqTable                                           \n",
    "from Bio.Align import AlignInfo \n",
    "from Bio import AlignIO, SeqIO \n",
    "                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f1d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================================================================================== \n",
    "data_path = '/data/cresswellclayec/covid_data/'                            \n",
    "root_dir = '/data/cresswellclayec/covid_data/' \n",
    "                                                        \n",
    "                                                                                                         \n",
    "                                                     \n",
    "                                                                \n",
    "#======================================================================================== \n",
    "data_path = '/data/cresswellclayec/covid_data/spikeprot1201/' \n",
    "root_dir = '/data/cresswellclayec/covid_data/'       \n",
    "                                    \n",
    "cpus_per_job = 40                                                      \n",
    "                                                     \n",
    "                                                                       \n",
    "# Swarm aligned file  \n",
    "msa_file = data_path+\"spikeprot1201.fasta\"\n",
    "msa_file = root_dir+\"omicron.fa\"\n",
    "ref_file = root_dir+\"spike_ref.fa\"                                     \n",
    "                     \n",
    "variant_name = 'Omicron'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fecefc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Omicron_unique_s0.npy'):\n",
    "\n",
    "    s0 = np.load(\"%s_s.npy\" % variant_name)                                                    \n",
    "    print(s0[0])                                                                                             \n",
    "    try:            \n",
    "        s0 = np.char.decode(s0)                                                  \n",
    "    except(UnicodeDecodeError):\n",
    "        # go through sequences individual and throw out baddies            \n",
    "        rows_to_remove = []\n",
    "        new_s0 = []                       \n",
    "        for i, arr in enumerate(s0):\n",
    "            try:\n",
    "                arr = np.char.decode(arr)\n",
    "                new_s0.append(arr)\n",
    "            except(UnicodeDecodeError):\n",
    "                rows_to_remove.append(i)\n",
    "                pass\n",
    "        s0 = np.array(new_s0)\n",
    "    print('unique values in s0 columns')\n",
    "    for col in range(s0.shape[1]):\n",
    "        print(np.unique(s0[:,col],return_counts=True))\n",
    "\n",
    "    s0 = np.delete(s0, -1, axis=1) # remove \n",
    "\n",
    "    unique_seqs = np.unique(s0,axis=0, return_index=True)\n",
    "    np.save('Omicron_unique_index.npy',unique_seqs[0])\n",
    "    s0 = unique_seqs[1] \n",
    "    np.save('Omicron_unique_s0.npy',s0)\n",
    "    print(unique_seqs[1])\n",
    "\n",
    "else:\n",
    "    s0_indx = np.load('Omicron_unique_index.npy')\n",
    "    s0 = np.load('Omicron_unique_s0.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7650ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sequence length:  1270\n",
      "tpdb (s_ipdb) is :  0\n",
      "#\n",
      "\n",
      "-------------------------Remove Gaps--------------------------#\n",
      "Shape of s is :  (487312, 1270)\n",
      "s = \n",
      " [['' '' '' ... '' '' '']\n",
      " ['I' 'F' 'V' ... 'H' 'Y' 'T']\n",
      " ['I' 'F' 'V' ... 'H' 'Y' 'T']\n",
      " ...\n",
      " ['X' 'X' 'X' ... 'H' 'Y' 'T']\n",
      " ['X' 'X' 'X' ... 'H' 'Y' 'T']\n",
      " ['X' 'X' 'X' ... 'H' 'Y' 'T']]\n",
      "['' '' '' ... '' '' '']\n",
      "['X' 'X' 'X' ... 'H' 'Y' 'T']\n",
      "(487312, 1270)\n",
      "s[tpdb] shape is  (1270,)\n",
      "s = \n",
      " [['' '' '' ... '' '' '']\n",
      " ['I' 'F' 'V' ... 'H' 'Y' 'T']\n",
      " ['I' 'F' 'V' ... 'H' 'Y' 'T']\n",
      " ...\n",
      " ['X' 'X' 'X' ... 'H' 'Y' 'T']\n",
      " ['X' 'X' 'X' ... 'H' 'Y' 'T']\n",
      " ['X' 'X' 'X' ... 'H' 'Y' 'T']]\n",
      "though s still has gaps, s[0] does not:\n",
      " ['' '' '' ... '' '' '']\n",
      "s shape is  (487312, 1270)\n",
      "Saving indices of reference sequence s[0](length=1270):\n",
      " [   0    1    2 ... 1267 1268 1269]\n",
      "#--------------------------------------------------------------#\n",
      "\n",
      "\n",
      "removing non aligned (lower case) columns in subject sequence:\n",
      "  [] \n",
      "\n",
      "bypassing duplicate search...\n",
      "(487312, 1270)\n",
      "In Data Processing Reference Sequence (shape= (1270,) ): \n",
      " ['' '' '' ... '' '' '']\n",
      "0\n",
      "After removing bad sequences, tpdb is now  0\n",
      "\n",
      "After removing bad sequences...\n",
      "tpdb (s_ipdb) is :  0\n",
      "(487312, 1270)\n",
      "found bad columns := []\n",
      "dealing with 30457.000000 sequences in each of the 16 sections\n",
      "in find_and_replace_parallel:  (487312, 1270)\n",
      "16\n",
      "(30457, 1270)\n",
      "parallel result:  (487312, 1270)\n",
      "dealing with 30457.000000 sequences in each of the 16 sections\n",
      "in find_and_replace_parallel:  (487312, 1270)\n",
      "16\n",
      "(30457, 1270)\n",
      "parallel result:  (487312, 1270)\n",
      "dealing with 30457.000000 sequences in each of the 16 sections\n",
      "in find_and_replace_parallel:  (487312, 1270)\n",
      "16\n",
      "(30457, 1270)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import data_processing as dp\n",
    "# data processing -- requires 36:00:00 time and 2000g mem\n",
    "preprocessing = False\n",
    "preprocessing = True\n",
    "if preprocessing:\n",
    "        # Preprocess data using ATGC\n",
    "        s0,cols_removed,s_index,s_ipdb,orig_seq_len = dp.data_processing_experiment(s0, variant_name, 0,\\\n",
    "                                gap_seqs=0.2,gap_cols=0.2,prob_low=0.004,conserved_cols_thresh=0.95,n_cpus=20)\n",
    "        print('after data processing' , s0.shape)\n",
    "else:\n",
    "        #if os.path.exists(input_data_file):\n",
    "        if os.path.exists(input_data_file):\n",
    "                with open(input_data_file, 'rb') as f:\n",
    "                        pf_dict = pickle.load(f)\n",
    "                f.close()\n",
    "\n",
    "                s0 = pf_dict['s0']\n",
    "                print(s0.shape)\n",
    "                s_index = pf_dict['s_index']\n",
    "                cols_removed = pf_dict['cols_removed']\n",
    "                s_ipdb = 0\n",
    "        else:\n",
    "                # Load appropriate files\n",
    "                print('loading files\\n')\n",
    "                aligned_genome_file = \"cov_processed.npy\"\n",
    "                removed_cols_file = \"covGEN_removed_cols.npy\"\n",
    "                s_index_file = \"covGEN_s_index.npy\"\n",
    "\n",
    "                s0 = np.load(aligned_genome_file,'c')\n",
    "                cols_removed = np.load(removed_cols_file)\n",
    "                s_index = np.load(s_index_file)\n",
    "                print('trimmed s loaded, ', s0.shape)\n",
    "\n",
    "                s_ipdb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfee08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
